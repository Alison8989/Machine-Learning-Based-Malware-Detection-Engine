import pefile
import os

norm_count_dic = {}
mal_count_dic = {}

def mean_calculate(cdict,name,new_data,n): #求平均值
    if(n == 1):
        cdict[name] = 0
        mean_pre = new_data
    else:
        mean_pre = cdict[name]
        mean_pre = mean_pre+(new_data - mean_pre)/n
    return mean_pre

def charastic_calculate(gdict,name,submode,value):#求掩膜序列
    ig = 0
    if(gdict.__contains__(name) == False):
        gdict[name]=[]
        n = 1
    else:
        n = 2
    for sm in submode:
        if((value & sm) > 0):
            if(n == 1):
                gdict[name].append(1)
            else:
                gdict[name][ig] += 1
        elif(n == 1):
            gdict[name].append(0)
        ig+=1

def val_add_one(gdict,name): #
    if (gdict.__contains__(name)):
        gdict[name] += 1
    else:
        gdict[name] = 1

dllmode = [0x0040, 0x0080, 0x0100, 0x0200, 0x0400, 0x0800, 0x8000]
tchamode = [0x00000020, 0x00000040, 0x00000080, 0x02000000, 0x10000000, \
            0x20000000, 0x40000000, 0x80000000]
rchamode = [0x00000020, 0x00000040, 0x00000080, 0x02000000, 0x10000000, \
            0x20000000, 0x40000000, 0x80000000]
high_freq_resource=[2,6,14,16]
#api包括进程行为、文件行为、网络行为、注册表行为等敏感行为统计
#可替换函数，相似函数
api_seq = [b'InternetOpenUrlA',
           b'NtReadVirtualMemory',
           b'CopyFile',
           b'DeleteFileA',
           b'RtlDecompressBuffer',
           b'Module32FirstW',
           b'OpenServiceA',
           b'CryptDecrypt',
           b'OutputDebugStringA',
           b'__anomaly__',
           b'WriteProcessMemory',
           b'NtGetContextThread',
           b'gethostbyname',
           b'CreateToolhelp32Snapshot',
           b'NtSetContextThread',
           b'Process32FirstW',
           b'Process32nextW',
           b'GetFileSizeEx',
           b'MoveFileWithProgressW',
           b'NtWriteVirtualMemory',
           b'URLDownloadToFileW',
           b'CopyAcquireContextW',
           b'CopyFileW',
           b'CopyFileA',
           b'FindNextFileA',
           b'WSASocketW',
           b'NtOpenDirectoryObject',
           b'ControlService',
           b'GetSystemWindowsDirectoryA',
           b'GetSystemDirectoryA',
           b'GetAsyncKeyState',
           b'IstrlenW',
           b'DisableThreadLibraryCalls',
           b'__adjust_fdiv',
           b'GetModuleHandle',
           b'CreateFileW',
           b'_initterm',
           b'RegDeleteKey',
           b'RegOpenKeyExA',
           b'RegOpenKeyExA',
           b'RegDeleteKeyEx',
           b'RegCreateKeyA',
           b'RegSetValueA',
           b'RegSetValueExA'
           ]
gsection_check = ['.textbss','.text', '.rdata', '.data','.reloc','.rdata','.bss','.rsrc','.edata','.idata','.debug']
def feature_count_ex(pfiles,count_dic,nums):
    api_len = 0
    if (hasattr(pfiles, 'DIRECTORY_ENTRY_IMPORT')):
        for importeddll in pfiles.DIRECTORY_ENTRY_IMPORT:
            for importedapi in importeddll.imports:
                api_len += 1
                if (importedapi.name in api_seq):
                    val_add_one(count_dic, importedapi.name.decode())  #API计数
        count_dic['NumberofAPIs'] = mean_calculate(count_dic,'NumberofAPIs', api_len, nums)
    else:
        if(nums == 1):
            count_dic['NumberofAPIs'] = 0
        else:
            count_dic['NumberofAPIs'] = mean_calculate(count_dic,'NumberofAPIs', 0, nums)

     #导入函数的可疑行为
    if (hasattr(pfiles, 'DIRECTORY_ENTRY_IMPORT')):
        suspicious_imports = set([b'LoadLibrary', b'GetProcAddress'])
        suspicious_imports_count = 0
        total_symbols = 0
        for imp_dll in pfiles.DIRECTORY_ENTRY_IMPORT:
            for symbol in imp_dll.imports:
                for suspicious_symbol in suspicious_imports:
                    if symbol and symbol.name and symbol.name.startswith(suspicious_symbol):
                        suspicious_imports_count += 1
                        break
                total_symbols += 1
        if suspicious_imports_count == len(suspicious_imports) and total_symbols < 20:
            val_add_one(count_dic, 'excu_func')
    # PE HEADER
    count_dic['NumberofSymbols'] = mean_calculate(count_dic,'NumberofSymbols', pfiles.FILE_HEADER.NumberOfSymbols,nums)
    count_dic['Numberofsection'] = mean_calculate(count_dic,'Numberofsection', pfiles.FILE_HEADER.NumberOfSections, nums)

    # OPTION HEADER
    if (hasattr(pfiles, 'OPTIONAL_HEADER')):
        for psection in pfiles.sections:
            if(psection.Name == b'.text\x00\x00\x00'):
                if(pfiles.OPTIONAL_HEADER.BaseOfCode >= psection.VirtualAddress and\
                               pfiles.OPTIONAL_HEADER.BaseOfCode < psection.VirtualAddress + psection.SizeOfRawData):
                    val_add_one(count_dic,'basecode')

        if(pfiles.OPTIONAL_HEADER.CheckSum == 0):
            val_add_one(count_dic,'checksum_0')

        charastic_calculate(count_dic, 'ophead_charistic', dllmode, pfiles.OPTIONAL_HEADER.DllCharacteristics)
        count_dic['codesize'] = mean_calculate(count_dic,'codesize',
                                              pfiles.OPTIONAL_HEADER.SizeOfCode, nums)
        count_dic['heapcommitsize'] = mean_calculate(count_dic,'heapcommitsize',
                                               pfiles.OPTIONAL_HEADER.SizeOfHeapCommit, nums)
        count_dic['SizeOfHeapRev'] = mean_calculate(count_dic,'SizeOfHeapRev',
                                                    pfiles.OPTIONAL_HEADER.SizeOfHeapReserve, nums)
        count_dic['SizeOfImage'] = mean_calculate(count_dic,'SizeOfImage',
                                                    pfiles.OPTIONAL_HEADER.SizeOfImage, nums)
        count_dic['SizeOfStackCommit'] = mean_calculate(count_dic,'SizeOfStackCommit',
                                                    pfiles.OPTIONAL_HEADER.SizeOfStackCommit, nums)
        count_dic['SizeOfStackRev'] = mean_calculate(count_dic,'SizeOfStackRev',
                                                    pfiles.OPTIONAL_HEADER.SizeOfStackReserve, nums)
        count_dic['SizeOfInitData'] = mean_calculate(count_dic,'SizeOfInitData',
                                                    pfiles.OPTIONAL_HEADER.SizeOfInitializedData, nums)
        count_dic['SizeOfUninitData'] = mean_calculate(count_dic,'SizeOfUninitData',
                                                     pfiles.OPTIONAL_HEADER.SizeOfUninitializedData, nums)
        if pfiles.OPTIONAL_HEADER.NumberOfRvaAndSizes > 0x10:
            val_add_one(count_dic, 'NumberOfRvaAndSizes_mal')
        #data directory
        gi = 0
        for dataDirect in pfiles.OPTIONAL_HEADER.DATA_DIRECTORY:
            count_dic['datadirectory'+str(gi)] = mean_calculate(count_dic,'datadirectory'+str(gi),
                                                           dataDirect.Size, nums)
            gi+=1
    else:
        count_dic['codesize'] = mean_calculate(count_dic,'codesize',
                                              0, nums)
        count_dic['heapcommitsize'] = mean_calculate(count_dic,'heapcommitsize',
                                               0, nums)
        count_dic['SizeOfHeapRev'] = mean_calculate(count_dic,'SizeOfHeapRev',
                                                    0, nums)
        count_dic['SizeOfStackCommit'] = mean_calculate(count_dic,'SizeOfStackCommit',
                                                   0, nums)
        count_dic['SizeOfImage'] = mean_calculate(count_dic,'SizeOfImage',
                                                    0, nums)
        count_dic['SizeOfStackRev'] = mean_calculate(count_dic,'SizeOfStackRev',
                                                   0, nums)
        count_dic['SizeOfInitData'] = mean_calculate(count_dic,'SizeOfInitData',
                                                    0, nums)
        count_dic['SizeOfUninitData'] = mean_calculate(count_dic,'SizeOfUninitData',
                                                     0, nums)
        #data directory
        gi = 0
        for dataDirect in pfiles.OPTIONAL_HEADER.DATA_DIRECTORY:
            count_dic['datadirectory'+str(gi)] = mean_calculate(count_dic,'datadirectory'+str(gi),
                                                           0, nums)
            gi+=1
    resid=[]
    #resource
    if (hasattr(pfiles, 'DIRECTORY_ENTRY_RESOURCE')):
        for rcsc in pfiles.DIRECTORY_ENTRY_RESOURCE.entries:
            temp_res_id = rcsc.id
            if (temp_res_id is None):
                temp_res_id = rcsc.struct.Id
            if (temp_res_id in high_freq_resource):
                val_add_one(count_dic,'resource'+ str(temp_res_id)) #统计关键资源的个数
            resid.append(temp_res_id)
    for i in range(24): #统计资源平均个数
        if(i+1) in resid:
            for rcsc in pfiles.DIRECTORY_ENTRY_RESOURCE.entries:
                temp_res_id = rcsc.id
                if (temp_res_id is None):
                    temp_res_id = rcsc.struct.Id
                if((i+1) == temp_res_id):
                    if(hasattr(rcsc,'directory')):
                        count_dic['resourcetype' + str(i+1)] = mean_calculate(count_dic,'resourcetype' + str(i+1),len(rcsc.directory.entries), nums)
                    else:
                        count_dic['resourcetype' + str(i + 1)] = mean_calculate(count_dic, 'resourcetype' + str(i + 1),
                                                                                0, nums)
                    break

        else:
            count_dic['resourcetype' + str(i+1)] = mean_calculate(count_dic,'resourcetype' + str(i+1),
                                                             0, nums)
    #debug

    # 导入四个section表
    gbret2 = True
    gbret3 = True
    gbret4 = True
    gbret5 = True
    gbret6 = True
    for psection in pfiles.sections:
        charastic_calculate(count_dic, psection.Name, tchamode, psection.Characteristics)
        if psection.Misc_VirtualSize > 0x10000000:
            if(gbret2):
                val_add_one(count_dic,'sec_Misc_VirtualSize_mal')
                gbret2 = False

        if ((psection.Characteristics & 0x80000000) and
            (psection.Characteristics &  0x20000000)):

            if psection.Name == b'PAGE' and pfiles.is_driver():
                # Drivers can have a PAGE section with those flags set without
                # implying that it is malicious
                pass
            else:
                if(gbret4):
                    val_add_one(count_dic,'sect_exc_write_pachage')
                    gbret4 =False
        try:
            psname = psection.Name.decode()
            if (psection.Characteristics & 0x20000000):
                if (psname == '.text' or psname == '.rsrc'):
                    if (gbret5):
                        val_add_one(count_dic, 'sect_exc_write_pachage')
                        gbret5 = False
            if (psname not in gsection_check):
                if (gbret6):
                    val_add_one(count_dic, 'unnormSectionName')
                    gbret6 = False
        except UnicodeDecodeError:
            if (gbret6):
                val_add_one(count_dic, 'unnormSectionName')
                gbret6 = False

PEfile_normal_Path = r'/home/ldy/download/benign'
PEfile_melicious_Path = r'/home/ldy/download/20131011003ndb'

def fakeFile_check(fpath):
    file_object = open(fpath, 'rb')
    try:
        e_magic = file_object.read(2)
    finally:
        file_object.close()
    if(e_magic == b'MZ'):
        return  True
    else:
        return False

def load_file(PEfile_Path):
    test_files = list()
    for dirpath, dirname, filenames in os.walk(PEfile_Path):
        for filename in (f for f in filenames if f.endswith('.exe')):
            rfpath = os.path.join(dirpath, filename)
            if 'user' in rfpath:
                continue
            else:
                if(fakeFile_check(rfpath)):  #只读取DOS文件
                    test_files.append(rfpath)
    return test_files

def load_malware_file(PEfile_Path):
    test_files = list()
    for dirpath, dirname, filenames in os.walk(PEfile_Path):
        for filename in  filenames:
            rfpath = os.path.join(dirpath, filename)
            if(fakeFile_check(rfpath)):  #只读取DOS文件
                test_files.append(rfpath)
    return test_files

def data_get(): #获取训练数据和测试数据
    gcroot_normal = load_file(PEfile_normal_Path)
    gcroot_melicious = load_malware_file(PEfile_melicious_Path)

    print("normal sample number is %d"%len(gcroot_normal))
    print("malware sample number is %d" % len(gcroot_melicious))

    for i in range(3000):
        try:
            p_files = pefile.PE(gcroot_normal[i], True)
            feature_count_ex(p_files, norm_count_dic, i+1)  #获取特征集
        except pefile.PEFormatError:
            continue
        finally:
            p_files.close()
    for i in range(3000):
        try:
            p_files = pefile.PE(gcroot_melicious[i], True)
            feature_count_ex(p_files, mal_count_dic, i + 1)  # 获取特征集
        except pefile.PEFormatError:
            continue
        finally:
            p_files.close()
if __name__ == '__main__':
    data_get()
    i = 0
    for k,v in norm_count_dic.items():
        if(mal_count_dic.__contains__(k)):
            if(isinstance(v, list)):
                print(k,v)
                print(k,mal_count_dic[k])
                i += 1
            else:
                if(v != 0 or (v == 0 and mal_count_dic[k] == 0)):
                    if(v != 0):
                        temp = abs(v-mal_count_dic[k])/v
                    else:
                        temp = 0
                    if(temp > 0.5):
                        print(k,":           ",v)
                        print(k,":           ",mal_count_dic[k])
                        i += 1
    print(i)

'''if pefile.pe.adjust_SectionAlignment(psection.VirtualAddress,
                                         pfiles.OPTIONAL_HEADER.SectionAlignment,
                                         pfiles.OPTIONAL_HEADER.FileAlignment) > 0x10000000:
     if (gbret3):
            val_add_one(count_dic, 'sect_VirtualAddress')
            gbret3 = False'''